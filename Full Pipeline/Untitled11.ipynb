{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIi8js5Ilsa9aY6yKJp/hd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meisisoiisme/FH-ML_PyTorch/blob/main/Untitled11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imoprts\n",
        "\n",
        "1.   ML Imports\n",
        "2.   Creating Dataset\n",
        "3.   Handeling Dataset info"
      ],
      "metadata": {
        "id": "skKlL3x4TBvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image, ImageDraw\n",
        "import os\n",
        "\n",
        "import csv\n",
        "import cv2\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "0m0_OT1cMX3p"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Images for Training your Network\n",
        "\n",
        "    # Example usage: Copy Code, remove lines containing information, adapt filepath if nessesary\n",
        "\n",
        "1.   ImageGenerator\n",
        "\n",
        "    output_directory = \"./training_images\"\n",
        "    image_gen = ImageGenerator(output_directory, num_classes=5, images_per_class=100, noise_factor=20)\n",
        "    image_gen.generate_images()\n",
        "\n",
        "2.   LandmarksImageGenerator\n",
        "\n",
        "    output_directory_landmarks = \"./training_images_with_landmarks\"\n",
        "    landmarks_gen = LandmarksImageGenerator(output_directory_landmarks, num_classes=5, images_per_class=100, noise_factor=20, num_landmarks=5)\n",
        "    landmarks_gen.generate_images_with_landmarks()\n",
        "\n",
        "    # Parameters\n",
        "    num_samples = 500\n",
        "    num_classes = 5\n",
        "    image_size = 64\n",
        "    batch_size = 32\n",
        "    num_epochs = 10\n",
        "    data_path = \"./training_images\"\n",
        "    landmarks_csv_path = \"./training_images_with_landmarks/landmarks.csv\"\n",
        "\n",
        "3.   CustomRandomDataset\n",
        "\n",
        "    # Create the custom dataset\n",
        "    custom_dataset = CustomRandomDataset(num_samples, num_classes, image_size, data_path, landmarks_csv_path)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jFKyzUH1TU2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageGenerator:\n",
        "    def __init__(self, output_dir, num_classes=5, images_per_class=100, image_size=(224, 224), noise_factor=20):\n",
        "        self.output_dir = output_dir\n",
        "        self.num_classes = num_classes\n",
        "        self.images_per_class = images_per_class\n",
        "        self.image_size = image_size\n",
        "        self.noise_factor = noise_factor\n",
        "\n",
        "    def generate_images(self):\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "        for class_idx in range(self.num_classes):\n",
        "            class_dir = os.path.join(self.output_dir, f\"class_{class_idx}\")\n",
        "            os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "            for i in range(self.images_per_class):\n",
        "                base_image = np.random.randint(0, 256, size=(self.image_size[1], self.image_size[0], 3), dtype=np.uint8)\n",
        "                noisy_image = base_image + np.random.randint(-self.noise_factor, self.noise_factor + 1, size=base_image.shape)\n",
        "                noisy_image = np.clip(noisy_image, 0, 255).astype(np.uint8)\n",
        "\n",
        "                pil_image = Image.fromarray(noisy_image)\n",
        "                image_path = os.path.join(class_dir, f\"image_{i}.png\")\n",
        "                pil_image.save(image_path)\n",
        "\n",
        "        print(f\"{self.num_classes} classes with {self.images_per_class} images each generated and saved in {self.output_dir}\")\n",
        "\n",
        "class LandmarksImageGenerator:\n",
        "    def __init__(self, output_dir, num_classes=5, images_per_class=100, image_size=(224, 224), noise_factor=20, num_landmarks=5):\n",
        "        self.output_dir = output_dir\n",
        "        self.num_classes = num_classes\n",
        "        self.images_per_class = images_per_class\n",
        "        self.image_size = image_size\n",
        "        self.noise_factor = noise_factor\n",
        "        self.num_landmarks = num_landmarks\n",
        "\n",
        "    def generate_images_with_landmarks(self):\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "        csv_file_path = os.path.join(self.output_dir, \"landmarks.csv\")\n",
        "        with open(csv_file_path, mode='w', newline='') as csv_file:\n",
        "            csv_writer = csv.writer(csv_file)\n",
        "            csv_writer.writerow(['Image Path', 'Class', 'Landmark 1 X', 'Landmark 1 Y', 'Landmark 2 X', 'Landmark 2 Y', '...'])\n",
        "\n",
        "            for class_idx in range(self.num_classes):\n",
        "                class_dir = os.path.join(self.output_dir, f\"class_{class_idx}\")\n",
        "                os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "                for i in range(self.images_per_class):\n",
        "                    base_image = np.random.randint(0, 256, size=(self.image_size[1], self.image_size[0], 3), dtype=np.uint8)\n",
        "                    noisy_image = base_image + np.random.randint(-self.noise_factor, self.noise_factor + 1, size=base_image.shape)\n",
        "                    noisy_image = np.clip(noisy_image, 0, 255).astype(np.uint8)\n",
        "\n",
        "                    landmarks = []\n",
        "                    for landmark_idx in range(self.num_landmarks):\n",
        "                        landmark_x = random.randint(0, self.image_size[0])\n",
        "                        landmark_y = random.randint(0, self.image_size[1])\n",
        "                        landmarks.extend([landmark_x, landmark_y])\n",
        "\n",
        "                    pil_image = Image.fromarray(noisy_image)\n",
        "                    image_path = os.path.join(class_dir, f\"image_{i}.png\")\n",
        "                    pil_image.save(image_path)\n",
        "\n",
        "                    csv_writer.writerow([image_path, class_idx] + landmarks)\n",
        "\n",
        "        print(f\"{self.num_classes} classes with {self.images_per_class} images each generated and saved in {self.output_dir}\")\n",
        "        print(f\"Landmark information saved in {csv_file_path}\")\n",
        "\n",
        "class CustomRandomDataset(Dataset):\n",
        "    def __init__(self, num_samples, num_classes, image_size, data_path=None, landmarks_csv_path=None):\n",
        "        self.num_samples = num_samples\n",
        "        self.num_classes = num_classes\n",
        "        self.image_size = image_size\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.data_path = data_path\n",
        "        self.landmarks_csv_path = landmarks_csv_path\n",
        "        self.num_landmarks = 5  # Assuming the default number of landmarks\n",
        "\n",
        "        self.load_data()\n",
        "\n",
        "    def load_data(self):\n",
        "        if self.data_path is not None:\n",
        "            for label in range(self.num_classes):\n",
        "                label_path = os.path.join(self.data_path, f\"{label}\")\n",
        "                if os.path.exists(label_path):\n",
        "                    class_images = [os.path.join(label_path, image_file) for image_file in os.listdir(label_path)]\n",
        "                    if len(class_images) == 0:\n",
        "                        print(f\"Warning: Class {label} has no images.\")\n",
        "                        continue\n",
        "\n",
        "                    # Ensure the number of samples does not exceed the available images\n",
        "                    num_samples_for_class = min(self.num_samples // self.num_classes, len(class_images))\n",
        "                    sampled_images = random.sample(class_images, num_samples_for_class)\n",
        "\n",
        "                    self.data.extend(sampled_images)\n",
        "                    self.labels.extend([label] * num_samples_for_class)\n",
        "\n",
        "    def load_image(self, image_path):\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        image = image.resize((self.image_size, self.image_size))\n",
        "        return transforms.ToTensor()(image)\n",
        "\n",
        "    def load_landmarks(self, csv_path):\n",
        "        landmarks = np.zeros((len(self.data), 2 * self.num_landmarks), dtype=np.float32)\n",
        "\n",
        "        with open(csv_path, mode='r') as csv_file:\n",
        "            csv_reader = csv.reader(csv_file)\n",
        "            next(csv_reader)  # Skip header row\n",
        "\n",
        "            for i, row in enumerate(csv_reader):\n",
        "                image_path, _, *landmark_values = row\n",
        "                image_index = self.data.index(image_path)\n",
        "                landmarks[image_index] = list(map(float, landmark_values))\n",
        "\n",
        "        return torch.tensor(landmarks)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.data[index]\n",
        "        label = self.labels[index]\n",
        "        image = self.load_image(image_path)\n",
        "        landmarks = self.load_landmarks(self.landmarks_csv_path)\n",
        "        return image, label, landmarks\n"
      ],
      "metadata": {
        "id": "LIu0JHLcS5RY"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINE CNN MODELS\n",
        "\n",
        "\n",
        "\n",
        "1.   CNN - Custom\n",
        "2.   AlexNet\n",
        "3.   LenNet5\n",
        "4.   ResNet - Pretrained Model: ResNet50"
      ],
      "metadata": {
        "id": "cjPDuokIVA_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes, image_size):\n",
        "        super(CNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(32 * (image_size // 4) * (image_size // 4), 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 6, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(6, 16, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(16, 120, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(120 * 53 * 53, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "class ResNetModel(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(ResNetModel, self).__init__()\n",
        "        self.model = models.resnet50(pretrained=True)\n",
        "        in_features = self.model.fc.in_features\n",
        "        self.model.fc = nn.Sequential(\n",
        "            nn.Linear(in_features, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "n40UL5haUsbf"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assuming you have already created the custom dataset and data loaders\n",
        "train_loader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Example usage:\n",
        "model_trainer = ModelTrainer(model, train_loader, val_loader, test_loader, criterion, optimizer, landmarks_csv_path=landmarks_csv_path, num_epochs=10)\n",
        "model_trainer.train()\n",
        "model_trainer.evaluate_and_save_results()"
      ],
      "metadata": {
        "id": "abxa01waXSqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelTrainer:\n",
        "    def __init__(self, model, train_loader, val_loader, test_loader, criterion, optimizer, landmarks_csv_path=None, num_epochs=30):\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.landmarks_csv_path = landmarks_csv_path\n",
        "        self.num_epochs = num_epochs\n",
        "\n",
        "    @property\n",
        "    def device(self):\n",
        "        return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def train(self):\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        for epoch in range(self.num_epochs):\n",
        "            self.model.train()\n",
        "            for inputs, labels, landmarks in self.train_loader:\n",
        "                inputs, labels, landmarks = inputs.to(self.device), labels.to(self.device), landmarks.to(self.device)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "            self.model.eval()\n",
        "            val_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels, landmarks in self.val_loader:\n",
        "                    inputs, labels, landmarks = inputs.to(self.device), labels.to(self.device), landmarks.to(self.device)\n",
        "\n",
        "                    outputs = self.model(inputs)\n",
        "                    loss = self.criterion(outputs, labels)\n",
        "                    val_loss += loss.item()\n",
        "\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "            print(f'Epoch {epoch+1}/{self.num_epochs}, Loss: {val_loss/len(self.val_loader)}, Validation Accuracy: {correct/total}')\n",
        "\n",
        "    def grad_cam(self, input_tensor, target_class=None):\n",
        "        self.model.eval()\n",
        "        device = next(self.model.parameters()).device\n",
        "\n",
        "        # Get the output from the final convolutional layer\n",
        "        final_conv_layer = None\n",
        "        for layer in self.model.children():\n",
        "            if isinstance(layer, nn.Conv2d):\n",
        "                final_conv_layer = layer\n",
        "\n",
        "        # Get the gradients with respect to the output of the final convolutional layer\n",
        "        self.model.zero_grad()\n",
        "        output = self.model(input_tensor.to(device))\n",
        "        if target_class is None:\n",
        "            target_class = torch.argmax(output)\n",
        "        output[:, target_class].backward()\n",
        "\n",
        "        # Get the feature map from the final convolutional layer\n",
        "        feature_maps = final_conv_layer.weight.grad\n",
        "        alpha = torch.mean(feature_maps, dim=(2, 3), keepdim=True)\n",
        "\n",
        "        # Perform weighted combination to get the heatmap\n",
        "        heatmap = torch.sum(alpha * feature_maps, dim=1, keepdim=True)\n",
        "        heatmap = nn.functional.relu(heatmap)\n",
        "\n",
        "        # Normalize the heatmap\n",
        "        heatmap /= torch.max(heatmap)\n",
        "\n",
        "        return heatmap\n",
        "\n",
        "    def overlay_heatmap(self, image, heatmap):\n",
        "        heatmap = heatmap.squeeze().cpu().numpy()\n",
        "        heatmap = np.uint8(255 * heatmap)\n",
        "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "        overlayed_image = cv2.addWeighted(image, 0.5, heatmap, 0.5, 0)\n",
        "        return overlayed_image\n",
        "\n",
        "    def evaluate_and_save_results(self):\n",
        "        self.model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels, landmarks in self.test_loader:\n",
        "                inputs, labels, landmarks = inputs.to(self.device), labels.to(self.device), landmarks.to(self.device)\n",
        "                outputs = self.model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Calculate confusion matrix\n",
        "        cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.colorbar()\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "OR461ihtXCLJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_directory = \"./training_images\"\n",
        "image_gen = ImageGenerator(output_directory, num_classes=5, images_per_class=100, noise_factor=20)\n",
        "image_gen.generate_images()\n",
        "\n",
        "output_directory_landmarks = \"./training_images_with_landmarks\"\n",
        "landmarks_gen = LandmarksImageGenerator(output_directory_landmarks, num_classes=5, images_per_class=100, noise_factor=20, num_landmarks=5)\n",
        "landmarks_gen.generate_images_with_landmarks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E7buLYDX1Du",
        "outputId": "b364aeff-17ba-43eb-9dbc-5dcf95cfe1c0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 classes with 100 images each generated and saved in ./training_images\n",
            "5 classes with 100 images each generated and saved in ./training_images_with_landmarks\n",
            "Landmark information saved in ./training_images_with_landmarks/landmarks.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "#num_samples = 100  # Make sure this is a positive value\n",
        "#num_classes = 5\n",
        "image_size = 64\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "data_path = \"./training_images\"\n",
        "landmarks_csv_path = \"./training_images_with_landmarks/landmarks.csv\"\n",
        "\n",
        "# Create the custom dataset\n",
        "custom_dataset = CustomRandomDataset(100, 5, image_size, data_path, landmarks_csv_path)\n",
        "custom_val_dataset = CustomRandomDataset(num_samples // 8, num_classes, image_size, data_path, landmarks_csv_path)\n",
        "custom_test_dataset = CustomRandomDataset(num_samples // 5, num_classes, image_size, data_path, landmarks_csv_path)\n",
        "\n",
        "# Assuming you have already created the custom dataset and data loaders\n",
        "train_loader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(custom_val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(custom_test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "AB_O6U0aXoZe",
        "outputId": "54665d74-b25b-4259-90e7-dc98d6386fd2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "num_samples should be a positive integer value, but got num_samples=0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-35635fc799ae>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Assuming you have already created the custom dataset and data loaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_val_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_test_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"num_samples should be a positive integer value, but got num_samples={self.num_samples}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_trainer = ModelTrainer(model, train_loader, val_loader, test_loader, criterion, optimizer, landmarks_csv_path=landmarks_csv_path, num_epochs=10)\n",
        "model_trainer.train()\n",
        "model_trainer.evaluate_and_save_results()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "id": "ovVzIGg2bhPH",
        "outputId": "d4ac7e6e-733a-4a4e-de32-73525924b268"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-de1a72a9583b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks_csv_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlandmarks_csv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_and_save_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-a84ebadc3811>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-b9eb1d2a289d>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "num_samples = 1000\n",
        "num_classes = 6\n",
        "image_size = 64\n",
        "batch_size = 32\n",
        "num_epochs = 30\n",
        "\n",
        "# Create the custom dataset\n",
        "custom_dataset = CustomRandomDataset(num_samples, num_classes, image_size)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Initialize the CNN model\n",
        "model = CNN(num_classes, image_size)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "# Use landmarks for images\n",
        "landmarks = {\n",
        "    0: \"Landmark for class 0\",\n",
        "    1: \"Landmark for class 1\",\n",
        "    2: \"Landmark for class 2\",\n",
        "    3: \"Landmark for class 3\",\n",
        "    4: \"Landmark for class 4\",\n",
        "    5: \"Landmark for class 5\"\n",
        "}\n",
        "\n",
        "for label, landmark in landmarks.items():\n",
        "    print(f\"Landmark for class {label}: {landmark}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7WBygG3MaI3",
        "outputId": "d968dc6f-a3de-4f55-cd14-4c7f7b8638d0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Loss: 1.796120285987854\n",
            "Epoch 2/30, Loss: 1.793994426727295\n",
            "Epoch 3/30, Loss: 1.7761523723602295\n",
            "Epoch 4/30, Loss: 1.8070263862609863\n",
            "Epoch 5/30, Loss: 1.7776235342025757\n",
            "Epoch 6/30, Loss: 1.7696566581726074\n",
            "Epoch 7/30, Loss: 1.822173833847046\n",
            "Epoch 8/30, Loss: 1.752305507659912\n",
            "Epoch 9/30, Loss: 1.5194302797317505\n",
            "Epoch 10/30, Loss: 1.474936842918396\n",
            "Epoch 11/30, Loss: 1.5054572820663452\n",
            "Epoch 12/30, Loss: 0.833915650844574\n",
            "Epoch 13/30, Loss: 0.7960186004638672\n",
            "Epoch 14/30, Loss: 0.26359787583351135\n",
            "Epoch 15/30, Loss: 0.3175039291381836\n",
            "Epoch 16/30, Loss: 0.2553141713142395\n",
            "Epoch 17/30, Loss: 0.10295675694942474\n",
            "Epoch 18/30, Loss: 0.03644685819745064\n",
            "Epoch 19/30, Loss: 0.08832476288080215\n",
            "Epoch 20/30, Loss: 0.031078940257430077\n",
            "Epoch 21/30, Loss: 0.022354021668434143\n",
            "Epoch 22/30, Loss: 0.01790250465273857\n",
            "Epoch 23/30, Loss: 0.01458773110061884\n",
            "Epoch 24/30, Loss: 0.014260511845350266\n",
            "Epoch 25/30, Loss: 0.009188798256218433\n",
            "Epoch 26/30, Loss: 0.009971672669053078\n",
            "Epoch 27/30, Loss: 0.00918307714164257\n",
            "Epoch 28/30, Loss: 0.006722867488861084\n",
            "Epoch 29/30, Loss: 0.007114055100828409\n",
            "Epoch 30/30, Loss: 0.005342339165508747\n",
            "Landmark for class 0: Landmark for class 0\n",
            "Landmark for class 1: Landmark for class 1\n",
            "Landmark for class 2: Landmark for class 2\n",
            "Landmark for class 3: Landmark for class 3\n",
            "Landmark for class 4: Landmark for class 4\n",
            "Landmark for class 5: Landmark for class 5\n"
          ]
        }
      ]
    }
  ]
}
